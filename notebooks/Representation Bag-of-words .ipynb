{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Load data, transform to Bag-of-words and fit Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "load_loc = '/home/jehi/Dropbox/DTU/DeepFactData/annotated/' #SPECIFY!\n",
    "with open(load_loc+\"data_matrix_sample_programs.pickle\",'rb') as f:\n",
    "        data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start time',\n",
       " 'end time',\n",
       " 'program_id',\n",
       " 'sentence_id',\n",
       " 'sentence',\n",
       " 'claim_idx',\n",
       " 'claim']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data['features']\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentences are for the data matrix (X), while the claims is for the outcome vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence is:\n",
      "\tDet har været ubehageligt.\n",
      "Claim is:\n",
      "\tNone\n",
      "\n",
      "Sentence is:\n",
      "\tjeg er meget fortvivlet ...\n",
      "Claim is:\n",
      "\tNone\n",
      "\n",
      "Sentence is:\n",
      "\tStatsministeren må overveje, om man kan have tillid til at den samme minister, som har været årsag til noget kritisabelt restriktivt, svingende ... alle de ord, som lige er nævnt om det er den rigtige person til også at rette op på alt det her sådan at vi kan få den vejledning, som vi kan forvente. Er ombudsmandens kritik alvorlig? Der er en kritik. Helt klart.\n",
      "Claim is:\n",
      "\tNone\n",
      "\n",
      "Sentence is:\n",
      "\tSelvfølgelig. DF vil have en stram udlændingepolitik.\n",
      "Claim is:\n",
      "\tDF vil have en stram udlændingepolitik\n",
      "\n",
      "Sentence is:\n",
      "\tDet er der meget, der tyder på. Man skal være meget godtroende for ikke at tænke, at der ligger andet bag.\n",
      "Claim is:\n",
      "\tNone\n",
      "\n",
      "Sentence is:\n",
      "\tDet er ikke en enkelt svipser. Det er helt konsekvent at man har vejledt forkert. Det viser ombudsmandens undersøgelse.\n",
      "Claim is:\n",
      "\tDet er helt konsekvent at man har vejledt forkert. Det viser ombudsmandens undersøgelse\n",
      "\n",
      "Sentence is:\n",
      "\tFor det andet er det tydeligt, at der er en tendens i misvejledningen.\n",
      "Claim is:\n",
      "\tNone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data['data'][:,4]\n",
    "y = data['data'][:,6]\n",
    "N = len(X)\n",
    "\n",
    "# Some examples\n",
    "for i in [21, 23, 33, 40, 48, 49, 50]: #range(100):\n",
    "    print('Sentence is:\\n\\t' + X[i])\n",
    "    print('Claim is:\\n\\t' + str(y[i])+'\\n')\n",
    "       \n",
    "# Now convert y to a binary indicator matrix (1 is claim, 0 no claim)\n",
    "y = np.asarray([y[i] is not None for i in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2346,    0],\n",
       "       [  76,  123]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Make a Bag-of-Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "# Fit the logit model\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(X=X_bow,y=y)\n",
    "ypred = logistic.predict(X_bow) \n",
    "\n",
    "# CM on traning data\n",
    "C = confusion_matrix(y, ypred)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the confusion matrix as probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.92180747,  0.        ],\n",
       "       [ 0.02986248,  0.04833006]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C/np.sum(C[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
